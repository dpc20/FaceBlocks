# FaceBlocks

1. 数据来源与处理

本项目使用了 IMDB-WIKI 数据集 作为数据来源。该数据集由 ETH Zurich 提供，包含超过 50 万张带有年龄和性别标签的人脸图像。这是当前公开的最大规模年龄预测数据集之一，同时为深度学习关键点识别任务提供了丰富的资源。

数据选取

我们从 IMDB-WIKI 数据集中精心挑选了 10,000 张人脸图像，以构建适用于深度学习关键点识别任务的高质量数据集。选取过程遵循以下标准：
	•	涵盖多样化的特征，包括 年龄段、性别 和 种族。
	•	包括不同的 面部表情 和 姿态。
	•	确保样本的多样性和代表性，以提高模型的泛化能力。

数据标注
所有选取的图像均经过严格的关键点标注过程，具体如下：
	•	标注严格遵循预定义的关键点规范，确保一致性和准确性。
	•	标注过程投入了大量人力和时间，以保证标注数据的高质量。

标注完成后的 10,000 张图像构成了本项目的核心训练数据集。

数据增强

为进一步提升模型性能，我们对标注完成的样本进行了 数据增强处理。主要增强操作包括：
	•	随机裁剪：模拟不同场景中的部分遮挡。
	•	水平翻转：扩展数据规模并增强对称性学习。
	•	旋转与缩放：提升对不同角度和拍摄距离的鲁棒性。
	•	颜色抖动：增强模型对光照变化的适应能力。
数据增强有效扩展了训练样本的规模，增加了数据的多样性，从而提升模型在实际应用中的鲁棒性和准确性。

数据处理总结

通过从 IMDB-WIKI 数据集 中选取样本、标注关键点并进行数据增强，我们构建了一个高质量的训练数据集，为深度学习关键点识别任务提供了坚实的基础。这些数据处理步骤确保了模型的性能和适用性，为实际应用场景中的关键点识别提供了可靠保障。

2. 模型介绍与训练

本项目围绕人体关键点识别任务，尝试了 DeepPose 和 YOLOv8 两种模型，并对比了其性能和适用性，最终选择 YOLOv8 作为模型的主要训练框架。以下是模型的简要介绍与训练细节：

（1） DeepPose模型

DeepPose 是一种开创性的基于深度学习的人体姿态估计模型，通过将人体关键点检测问题表述为回归任务，利用深度卷积神经网络（CNN）直接预测关键点的二维坐标。其核心包括：
	•	全局回归模型：通过卷积神经网络提取全局特征，直接预测关键点位置。
	•	级联回归模型：逐步细化关键点预测结果，提升定位精度。

本项目使用 ResNet50 作为特征提取骨干网络，在标注好的数据集上进行了迁移学习。损失函数尝试了 L1 Loss、Smooth-L1 Loss 和 Wing Loss，最终选择了表现最优的 Wing Loss。经过 100 轮训练后，模型在训练集和测试集上的损失趋于稳定，但由于 DeepPose 更倾向于学习关键点的绝对位置而非相对位置，其泛化能力表现不佳，尤其在姿态复杂或非正位样本上误差较大。

（2） YOLOv8模型

YOLOv8 是 YOLO 系列的最新版本，采用全新的网络结构与训练方法，具备高精度和高效推理性能，特别适合实时场景中的人体关键点识别。YOLOv8 的特点包括：
	•	网络优化：引入 Efficient Layer Aggregation Networks (ELAN) 模块，增强对复杂场景的特征提取能力。
	•	增强的损失函数：针对小物体和重叠物体进行了优化。
	•	自动化数据增强：使用 AutoMix 和策略自适应增强技术，提高模型泛化能力。
	•	更高的推理效率：量化与剪枝优化使其在嵌入式设备中表现出色。

在本项目中，YOLOv8 的关键点检测模块通过在 COCO 数据集预训练的 YOLOv8s-pose 模型进行微调。训练了 50 轮，最终模型在输出稳定性上显著优于 DeepPose，有效减少了关键点抖动噪音，尤其在游戏应用中表现出更高的鲁棒性。

（3） 模型选择

在对比 DeepPose 和 YOLOv8 的过程中，发现 YOLOv8 在稳定性和泛化能力上均优于 DeepPose，特别是在实时检测任务中，其高效性和低噪声输出使其更适合游戏应用场景。因此，最终选择 YOLOv8 作为关键点识别的核心模型。

通过本项目的模型设计与训练，展示了不同技术路径在人体关键点检测任务中的适用性，同时为游戏与关键点结合的场景提供了创新性的解决方案。

